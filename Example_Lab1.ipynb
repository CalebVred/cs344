{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Example Lab1",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "39b9d6c5d896462eaa484d6b9fc37143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_478f0f9e6c3442e9ab1817b56da65cd1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49bbcbe5c7054f7bad8b942bdcd3eaa1",
              "IPY_MODEL_3bb81ab6ed764f41b87c8eb797ac7730"
            ]
          }
        },
        "478f0f9e6c3442e9ab1817b56da65cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49bbcbe5c7054f7bad8b942bdcd3eaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d966bb520964d0198fa8fba9023a5d4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de88f14ab34d4e2782f7c6030fd1d611"
          }
        },
        "3bb81ab6ed764f41b87c8eb797ac7730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45eb8944a92d4561ab9db5327a232555",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [03:02&lt;00:00, 479kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_778e52014daf4195a12c6700228de665"
          }
        },
        "8d966bb520964d0198fa8fba9023a5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de88f14ab34d4e2782f7c6030fd1d611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45eb8944a92d4561ab9db5327a232555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "778e52014daf4195a12c6700228de665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcarnold/cs344/blob/main/Example_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kMY1gBEbo9L"
      },
      "source": [
        "try: import fastbook\n",
        "except ImportError: import subprocess; subprocess.run(['pip','install','-Uq','fastbook'])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX9xV2Zkbmog"
      },
      "source": [
        "# Lab 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufTfhTEabmom"
      },
      "source": [
        "We're going to start with the cat-vs-dog classifier that we built in chapter 1 and try changing a few things.\n",
        "\n",
        "Before we get started, discuss with your partner how you think each one of these changes would change the performance of the classifier. Write your answers below.\n",
        "\n",
        "> Train the model on less data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsRw7-lRbmom"
      },
      "source": [
        "It will be less accurate due to less base data for the AI to work with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE-BO4iWbmon"
      },
      "source": [
        "> Use an architecture with fewer layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K44VTxMpbmon"
      },
      "source": [
        "It will be less accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2GVx39bmon"
      },
      "source": [
        "> Have it predict the breed of pet instead of just cat/dog."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ydu-scbmoo"
      },
      "source": [
        "It is trying to determine different things. One is classication (cat/dog) and the other is regression (breed of dog)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBgodPM3bmoo"
      },
      "source": [
        "Now let's start. You might see a task like this:\n",
        "\n",
        "> Train a classifier to distinguish between images of cats and dogs.\n",
        "> \n",
        "> * Use the [Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/).\n",
        "> * Fine-tune a 34-layer ResNet model for 1 epoch\n",
        "> * Report the error rate on a held-out validation set of 20% of the data.\n",
        "\n",
        "The first code block from chapter 1 accomplishes this task. Retype or copy-paste it here, but add some comments if you haven't already:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcRbbRUybmoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "39b9d6c5d896462eaa484d6b9fc37143",
            "478f0f9e6c3442e9ab1817b56da65cd1",
            "49bbcbe5c7054f7bad8b942bdcd3eaa1",
            "3bb81ab6ed764f41b87c8eb797ac7730",
            "8d966bb520964d0198fa8fba9023a5d4",
            "de88f14ab34d4e2782f7c6030fd1d611",
            "45eb8944a92d4561ab9db5327a232555",
            "778e52014daf4195a12c6700228de665"
          ]
        },
        "outputId": "35266ad1-0fdd-4e75-df84-a10bc1e1dee3"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x): return x[0].isupper()\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))\n",
        "\n",
        "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39b9d6c5d896462eaa484d6b9fc37143",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.157933</td>\n",
              "      <td>0.032194</td>\n",
              "      <td>0.008796</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.056920</td>\n",
              "      <td>0.047423</td>\n",
              "      <td>0.011502</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7cybZBpbmoq"
      },
      "source": [
        "**Question**: Use `learn.fine_tune?` to bring up the documentation. Based on that:\n",
        "\n",
        "1. What does the \"1\" parameter to `fine_tune` do?\n",
        "2. What do you think the two different progress bars probably represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUl5s5kbmor"
      },
      "source": [
        "**Question**: Give an example filename for one of the images in the dataset. Does the dataset label it as a cat or a dog? How can you tell?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LixD2wvSbmos"
      },
      "source": [
        "#Abc.jpg would be labeled as a cat because it starts with a capital letter."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBPsvL4sbmot"
      },
      "source": [
        "**Question**: How many images were in the training set? Validation set? (How can you easily tell?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFZncKn7bmot"
      },
      "source": [
        "#80% was in the training set and 20% was in the validation set."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QskAQcSUbmot"
      },
      "source": [
        "You can tell by the parameter valid_pct = 0.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBYMBN0pbmot"
      },
      "source": [
        "**Question**: About how many of those images were classified correctly?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1axXc5-bmot"
      },
      "source": [
        "7390 - (7390 * error%) = 7315 images were classified correctly, or about 98.9%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKfVnHgTbmou"
      },
      "source": [
        "\n",
        "\n",
        "**Question**: What is the output of the model?\n",
        "\n",
        "1. whether the image contains one cat (`True`) or many cats (`False`)\n",
        "\n",
        "*2. whether the image contains a cat (`True`) or a dog (`False`)*\n",
        "\n",
        "3. what breed of cat or dog is in the image (`British_Shorthair`, `chihuahua`, etc.)\n",
        "4. the name of the animal in the image (`Fido`, `Whiskers`, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNH4MldTbmov"
      },
      "source": [
        "**Exercise**: Use an 18-layer ResNet instead (`resnet18`). How does the error rate compare?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsNfPaiAbmov"
      },
      "source": [
        "#The error rate is smaller with resnet18 (0.010149 to 0.008796)."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWX9mOlWbmov"
      },
      "source": [
        "Consider the We just changed the *architecture*, but not anything else. We could also change:\n",
        "\n",
        "* The *data*: give it different images (or more or fewer of the same images)\n",
        "* The *task*: have it try to predict something different\n",
        "* The *hyperparameters*: train it a different way, e.g., let it train longer (more epochs) or adjust itself faster (higher learning rate)\n",
        "\n",
        "Let's change the data.\n",
        "\n",
        "**Exercise**: Hold out 90% (instead of 20%) of the data for validation. (How many images will the training set have now?) How does the accuracy compare?\n",
        "\n",
        "(*Think*: Should you use the resnet18 or the resnet34 model here? What are the pros and cons?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrtpAmERbmov"
      },
      "source": [
        "#10% in the training set and 90% in the validation set. \n",
        "#The accuracy went down with an error rate of 0.031123 compared to 0.010149."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P62F9c5Ybmov"
      },
      "source": [
        "**Question**: How might we change the *task*? That is, what different things could we have the model output?\n",
        "\n",
        "Think about that for a moment.\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "The model's outputs are (generally) determined by what sort of *labels* we have for our data. Let's have a look at what the files are named. We could open up our data directory, or we could look in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pzUSrHvbmov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e3bed7-f127-428d-c742-edf571e31426"
      },
      "source": [
        "[o.name for o in get_image_files(path)][:10] # show only the first 10"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Birman_10.jpg',\n",
              " 'Maine_Coon_270.jpg',\n",
              " 'pomeranian_123.jpg',\n",
              " 'havanese_158.jpg',\n",
              " 'Egyptian_Mau_121.jpg',\n",
              " 'havanese_56.jpg',\n",
              " 'chihuahua_198.jpg',\n",
              " 'wheaten_terrier_35.jpg',\n",
              " 'boxer_22.jpg',\n",
              " 'staffordshire_bull_terrier_202.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H35uSDnbmo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3826fd-5826-47f6-a423-4380c0aadb09"
      },
      "source": [
        "# Aside: fastai added a nice trick that makes this easy:\n",
        "get_image_files(path).attrgot('name')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#7390) ['Birman_10.jpg','Maine_Coon_270.jpg','pomeranian_123.jpg','havanese_158.jpg','Egyptian_Mau_121.jpg','havanese_56.jpg','chihuahua_198.jpg','wheaten_terrier_35.jpg','boxer_22.jpg','staffordshire_bull_terrier_202.jpg'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0IUpGgvbmo2"
      },
      "source": [
        "So it looks like we should be able to get the *breed* pretty easily. All we need to do is strip off everything after the last underscore. (Is this exercise familiar?)\n",
        "\n",
        "These names are passed to the `name_func`. So all we need to do is strip off the number and file extension at the end to get the breed.\n",
        "\n",
        "**Exercise**: Write a function called `get_breed` that takes a string and strips off everything after the last underscore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRjCWmVvbmo2"
      },
      "source": [
        "def get_breed(file_name):\n",
        "    return file_name[:file_name.rfind('_')]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YozVamvNbmo2"
      },
      "source": [
        "Now let's test that function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srdkdQR3bmo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0a92da-e912-4fac-f088-1721d8182f7e"
      },
      "source": [
        "# When a Python expression gets complicated, I like to spread it onto multiple lines.\n",
        "# Often an expression is already inside some parentheses so you can just press Enter,\n",
        "# but for \"top-level\" expressions we need this trick of surrounding the whole thing in parens.\n",
        "# Aside from the attrot and map, this is just standard Python here, no special magic.\n",
        "(\n",
        "    get_image_files(path)\n",
        "    .attrgot('name')\n",
        "    .map(get_breed)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#7390) ['Birman','Maine_Coon','pomeranian','havanese','Egyptian_Mau','havanese','chihuahua','wheaten_terrier','boxer','staffordshire_bull_terrier'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA4cY9WObmo4"
      },
      "source": [
        "Let's check how many of each breed we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGd8z_Gjbmo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da069ccd-af28-4f17-d0f9-f0ba33e1904c"
      },
      "source": [
        "Counter(\n",
        "    get_image_files(path)\n",
        "    .attrgot('name')\n",
        "    .map(get_breed)\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Abyssinian': 200,\n",
              "         'Bengal': 200,\n",
              "         'Birman': 200,\n",
              "         'Bombay': 200,\n",
              "         'British_Shorthair': 200,\n",
              "         'Egyptian_Mau': 200,\n",
              "         'Maine_Coon': 200,\n",
              "         'Persian': 200,\n",
              "         'Ragdoll': 200,\n",
              "         'Russian_Blue': 200,\n",
              "         'Siamese': 200,\n",
              "         'Sphynx': 200,\n",
              "         'american_bulldog': 200,\n",
              "         'american_pit_bull_terrier': 200,\n",
              "         'basset_hound': 200,\n",
              "         'beagle': 200,\n",
              "         'boxer': 200,\n",
              "         'chihuahua': 200,\n",
              "         'english_cocker_spaniel': 200,\n",
              "         'english_setter': 200,\n",
              "         'german_shorthaired': 200,\n",
              "         'great_pyrenees': 200,\n",
              "         'havanese': 200,\n",
              "         'japanese_chin': 200,\n",
              "         'keeshond': 200,\n",
              "         'leonberger': 200,\n",
              "         'miniature_pinscher': 200,\n",
              "         'newfoundland': 200,\n",
              "         'pomeranian': 200,\n",
              "         'pug': 200,\n",
              "         'saint_bernard': 200,\n",
              "         'samoyed': 200,\n",
              "         'scottish_terrier': 199,\n",
              "         'shiba_inu': 200,\n",
              "         'staffordshire_bull_terrier': 191,\n",
              "         'wheaten_terrier': 200,\n",
              "         'yorkshire_terrier': 200})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mitvobbmo4"
      },
      "source": [
        "Now, let's change the model to output the breed instead of whether or not the thing is a cat.\n",
        "\n",
        "**Predict**: Will the accuracy number go up or down? Why?\n",
        "\n",
        "**Exercise**: Go back to the initial setup (ResNet-34 model and full dataset), but instead of predicting cat vs dog, now predict breed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtjkMjzKbmo4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "8de732df-6820-4346-ba15-75e695f1e0af"
      },
      "source": [
        "#Our prediction is that the accuracy will plummet because \n",
        "#there are many more categories for it to distinguish between meaning chance for the error is larger.\n",
        "\n",
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def get_breed(x): return x[:x.rfind('_')]\n",
        "\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=get_breed, item_tfms=Resize(224))\n",
        "\n",
        "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.493640</td>\n",
              "      <td>0.307790</td>\n",
              "      <td>0.104195</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='6' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      6.52% [6/92 00:05<01:13 0.4715]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ylbi1Mbmo5"
      },
      "source": [
        "**Reflect**: What accuracy do you get with this classifier? Is it better or worse? How can you tell?\n",
        "\n",
        "-The error rate seems to be worse? (0.105548 / 0.089986) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2RZMF85bmo5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX70fq5ibmo5"
      },
      "source": [
        "# Open-ended!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IYOlX41bmo5"
      },
      "source": [
        "If you got through that quickly, now try one or two more experiments of your own choice. For example, you might try changing a hyperparameter (epochs, learning rate, ...), try a different dataset size, try different random seeds, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvCsJEt2bmo5"
      },
      "source": [
        "# Summarize\n",
        "\n",
        "1. Write a short summary of the results of all of the experiments you performed in this lab.\n",
        "    - We learned that ResNet18 (18 layers) is more accurate than ResNet34 (34 layers), in this experiment. \n",
        "    - We learned that 80% training set and a 20% validation set appears to be optimal as opposed to 90% training set and 10% validation set. This shows the importance of the validation set as it can help correct mistakes made in training set. \n",
        "    - We learned that training an AI with many categories is less accurate than training an AI with fewer categories due to a greater opportunity for error, classification vs. regression.\n",
        "    \n",
        "2. Reflect on how confident you are that each of those comparisons didn't just happen by chance. Also reflect on which of the results would be likely to generalize to other tasks.\n",
        "    - We are confident that these comparisons did not happen by coincidence because we re-ran the kernel and retrieved similar results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGIYwxFebmo5"
      },
      "source": [
        "# Wrap-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oanAgrb6bmo6"
      },
      "source": [
        "* Make sure you Save this notebook.\n",
        "* From the Kernel menu, select \"Restart and Run All\". This will take a few minutes, but will ensure that all of your code still runs. Double-check that your results still make sense.\n",
        "* Commit and push. Check that your notebook is visible on GitHub."
      ]
    }
  ]
}