---
title: 'Discussion 2: Facial Recognition'
author: Ken Arnold
date: '2021-02-26'
slug: discussion-2-facial-recognition
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-02-26T10:26:23-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

## Facial Recognition Data

> Facial recognition technologies pose complex ethical and technical challenges. Neglecting to unpack this complexity- to measure it, analyze it and then articulate it to others -is a disservice to those, including ourselves, who are most impacted by its careless deployment.
>
> [About Face: A Survey of Facial Recognition Evaluation](https://arxiv.org/abs/2102.00813), presented at the AAAI 2020 Workshop on AI Evaluation

Some of you may already be familiar with some of the issues that have been raised about facial recognition systems. (If not, scroll down...) Since we've now spent some time looking at how data affects a machine learning algorithm, let's talk about how the *data* used to train facial recognition systems might matter.

1.  Please *skim* [this paper on facial recognition evaluation](https://arxiv.org/abs/2102.00813) and [Tech Review's coverage](https://www.technologyreview.com/2021/02/05/1017388/ai-deep-learning-facial-recognition-data-history/) of the paper.

2.  Choose one aspect that stood out to you and read it in more detail. (Maybe follow one of the citations to learn more.)

3.  Make a post on the Moodle discussion forum. You might choose one or more of:

    1.  A *quote* from the paper or article

    2.  What you found interesting about it.

    3.  A question you have

    4.  Something you disagree with or an assumption you want to question

4.  *optional but encouraged* Watch the [2-minute trailer for Coded Bias](https://www.codedbias.com/about).

If this is interesting to you, mark your calendars for a screening of the film [Coded Bias](https://www.codedbias.com/about) on [PBS on March 22](https://www.pbs.org/independentlens/films/coded-bias/).

## Facial Recognition Background

If you haven't yet engaged with what facial recognition does and what might go wrong with it, get some background before you engage the above. Here's a few resources (DATA 202 students will recognize these):

-   [**GenderShades**](http://gendershades.org/index.html) summary video

-   Project Green Light (Detroit)

    -   Tawana Petty Interview (second video on [**this page**](https://esc.umich.edu/project-green-light/))

    -   Hill, K. (2020, July 24). [**Wrongfully Accused By an Algorithm**](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html). The New York Times.

-   Portland's facial recognition ordinance: coverage by [**The Hill**](https://thehill-com.cdn.ampproject.org/c/s/thehill.com/policy/technology/515772-portland-adopts-landmark-facial-recognition-ordinance?amp)

-   <https://www.nytimes.com/2019/07/10/opinion/facial-recognition-race.html>

See the UMich ESC [**Project Green Light**](https://esc.umich.edu/project-green-light/) site for some other articles.
