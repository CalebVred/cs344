---
title: 'Discussion 2: Facial Recognition'
author: Ken Arnold
date: '2021-02-26'
slug: discussion-2-facial-recognition
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-02-26T10:26:23-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

## Facial Recognition Data

> Facial recognition technologies pose complex ethical and technical challenges. Neglecting to unpack this complexity- to measure it, analyze it and then articulate it to others -is a disservice to those, including ourselves, who are most impacted by its careless deployment.
>
> [About Face: A Survey of Facial Recognition Evaluation](https://arxiv.org/abs/2102.00813), presented at the AAAI 2020 Workshop on AI Evaluation

Some of you may already be familiar with some of the issues that have been raised about facial recognition systems. (If not, scroll down...) Since we've now spent some time looking at how data affects a machine learning algorithm, let's talk about how the *data* used to train facial recognition systems might matter.

**Shalom in Data** We saw last week how God put so much *good* data in the created world, and created humans in his image being able to *see* that data rightly and *act* accordingly. But sin has corrupted the data we get from the world and the *actions* that we take based on it. Let's look at one example of how data can be corrupted (on the input) and lead to corrupted actions (on the output).

1.  Please *skim* [this paper on facial recognition evaluation](https://arxiv.org/abs/2102.00813) and [Tech Review's coverage](https://www.technologyreview.com/2021/02/05/1017388/ai-deep-learning-facial-recognition-data-history/) of the paper.

2.  Choose one aspect that stood out to you and read it in more detail. (Maybe follow one of the citations to learn more.)

3.  Make a post on the Moodle discussion forum. You might choose one or more of:

    1.  What *quote* from the paper or article stood out to you?

    2.  What did you find interesting or surprising?

    3.  What questions do you have?

    4.  Did you notice anything you disagree with or an assumption you want to question?

    5.  These readings are from a secular perspective; as you read did you notice any places where a Christian might go deeper or make different conclusions?

4.  *optional but encouraged* Watch the [2-minute trailer for Coded Bias](https://www.codedbias.com/about).

If this is interesting to you, mark your calendars for a screening of the film [Coded Bias](https://www.codedbias.com/about) on [PBS on March 22](https://www.pbs.org/independentlens/films/coded-bias/).

## General Reflection Questions (optional for this activity)

As we look at several different technologies throughout this semester, we will ask some of the same questions about each of them. Here's the list so far. You don't need to specifically engage them for this activity, but they may be helpful for prompting your thinking:

-   How does it work?

-   What resources does it need? What resources does it produce?

-   What value does it produce for an organization that uses it?

-   Besides its primary use, what are other consequences (within and outside the organization) of its deployment? Think of people affected, resources consumed or produced, value generated, etc.

-   What are comparable or alternative non-AI products / technologies? What are real-world analogies for this technology (in terms of purpose or function)?

-   What ways of looking at or thinking about people does it emphasize? De-emphasize?

-   What are its limitations? Which limitations are most fundamental?

## Facial Recognition Background

If you haven't yet engaged with what facial recognition does and what might go wrong with it, get some background before you engage the above. Here's a few resources (DATA 202 students will recognize these):

-   [**GenderShades**](http://gendershades.org/index.html) summary video

-   Project Green Light (Detroit)

    -   Tawana Petty Interview (second video on [**this page**](https://esc.umich.edu/project-green-light/))

    -   Hill, K. (2020, July 24). [**Wrongfully Accused By an Algorithm**](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html). The New York Times.

-   Portland's facial recognition ordinance: coverage by [**The Hill**](https://thehill-com.cdn.ampproject.org/c/s/thehill.com/policy/technology/515772-portland-adopts-landmark-facial-recognition-ordinance?amp)

-   <https://www.nytimes.com/2019/07/10/opinion/facial-recognition-race.html>

See the UMich ESC [**Project Green Light**](https://esc.umich.edu/project-green-light/) site for some other articles.
