---
title: "CS 344: Artificial Intelligence"
semester: "Spring 2021"
time: "11:30am"
start: "02/03/2021"
end: "04/16/2021"
past_week: 8
days: "MWF"
---


===03/04/2021

Note:: Advising Day

===03/23/2021

Note:: Advising Day

===04/14/2021

Note:: Advising Day


===04/04/2021
Note:: Easter

===05/9/2021

Note:: Friday Class Schedule

===05/7/2021

Note:: Study Day




===02/03/2021
Topic:: Kickoff, [Teachable Machine](https://teachablemachine.withgoogle.com/train/image), Logistics
Read:: Syllabus
Resources:: [Day 1 slides](/slides/w1d1/w1d1-intro.html)

Log::
  * 15+ min: think-pair-share about intelligence in Scripture (Psalm 103 example)
  * 5 min: bare minimum logistics
  * 15 min: Teachable Machine in partners
  * 5 min: debrief Teachable Machine
  * 5 min: objectives and send-off

Reflection::
  * People got talking with each other.
  * People reflected on God's word and what it means for our class, in a way that
    will give persective to the rest of our time together.
  * People got experience with machine learning and data collection.

  It wasn't perfect, but it was the right way to start the semester.

Next time::
  * Shorter Scripture passage
  * Frame the Scripture TPS with an example?
  * Maybe have a backup device in case Teachable Machine doesn't work for someone?

===02/04/2021
Quiz:: Python review

  * Boolean function: does this string start with a capital letter?
  * func returning a string: strip everything after (and including) the last underscore
  * do this for every string in a list, without rewriting the logic
  * return the sum of the square of every element in a list

  ```
  x = 'grizzly', 'white', 'teddy'
  a,b,c = x
  print(c)
  ```

  ```
  class Thing:
    def __getitem__(self, x): return f"Item {x}"
    def __getattr__(self, x): return f"Attr {x}"

  # explain the result of each of the following lines.
  y = Thing
  y.abc
  y['abc']
  z = y()
  z.abc
  z['abc']
  z[abc]
  ```

  Suppose you have `def do_to_all(x, f): return [f(o) for o in x]`

  Fill in the blank:

  ```
  paths = ['a_b1', 'b_c2']
  stripped_paths = do_to_all(paths, _____)
  print(paths)
  ```

  So that you get ['a', 'b']. Explain why this works.



===
Topic:: Lab 0: Warm-up

Notes::
  <details><summary>Lab Logistics</summary>

  * Come to Maroon lab. Fill in computers as available, others stand around the sides of
    the room (at safe distance) for overview (then move to Gold lab)
  * People at Maroon lab computers: **reboot into Linux**

  </details>

===
Topic:: Lab 1 (Chapter 1)

Prep::
  * read [DL4C chapter 1](https://github.com/fastai/fastbook/blob/master/01_intro.ipynb)
  * Watch [Lesson 1 Video](https://course.fast.ai/videos/?lesson=1)
  * Complete reading quiz


Next Time::
  * Simplify the questions.
  * Give some guidance on logistics (remind Lab 0: github, Maroon lab not VMs, full-screen trick)
  * Have students make some observations about individual images.


===
Topic:: Guest lecture: KVL

Due:: Reflection 1

===02/11/2021
Quiz:: Quiz 2

===
Topic:: Guest lecture: KVL

===
Topic:: Lab 1 recap ([slides](/slides/w2d1/w2d1-debrief.html), [code](https://nbviewer.jupyter.org/github/kcarnold/cs344/blob/main/src/Data_Loading_Code.ipynb))

Read:: [DL4C chapter 2](https://colab.research.google.com/github/fastai/fastbook/blob/master/02_production.ipynb)
    *note: ignore the implementation of `class DataLoaders`.*
Watch:: [Lesson 2 Video](https://course.fast.ai/videos/?lesson=2)
Quiz:: Reading Quiz 2

* Review lab 1. (peer feedback)
* Give feedback about weekly reviews
* Announce hw1

===
Topic:: Review, Intro to AI Ethics [slides](/slides/w2d2/w2d2-ethics.html)

Read::
  * [DL4C chapter 3](https://github.com/fastai/fastbook/blob/master/03_ethics.ipynb) until "Topics in Data Ethics"
  * the **table of contents** of the [January 2021 Montreal AI Ethics Report](https://montrealethics.ai/wp-content/uploads/2021/01/State-of-AI-Ethics-Report-January-2021.pdf)

Due:: Discussion post about a topic that caught your eye (before class)

Due:: Reflection 2

===
Topic:: Lab 1 extension, homework work

* First peel-back-the-covers:
* Use DataBlocks API instead of default ImageDataLoaders
* show cat/dog batches
* compare performance with/without augmentation

Make sure this sets up well for hw1:
* What experiments do I hope students try for hw1
* How can I encourage meaningful comparisons? (Script to do a training run multiple times and collect evaluation outputs?)

Retrospective:

* Some students still struggled with git. Lots of wasted time there.
* Execution environment and collaboration is problematic.
* Unclear what exactly the goal was.

Next year: definitely do something easier than Yelp.


I'm wondering: should I move lab out of class? e.g., hold (unofficial) lab hours.

===
Topic:: Conceptual Review [Slides](/slides/w3d1/w3d1-concepts.html)

Plan::

  Logistics
  * Should I "override email prefs" for all Piazza announcements?
  * Shrink old calendar entries

  Core
  * Datasets: train/valid/test
  * Data loading: what problem does it solve
  * Confusion matrix; FP/FN / precision/recall
  * Batches
  * Data augmentation
    * analogies for overfitting
      * kids' puzzle
      * covid vaccines / antibodies / variants
      * background identification problem / dumbbell vs arm
    * what specific transforms can be used
  * Running experiments
    * Reproducibility
    * Variability
  * Previews:
    * loss
    * NN architectures

  Tools:

  * JSON newline-delimited
  * Jupyter Notebooks
    * execution order issues
  * github
    * stage / commit / push
    * nbdime?
    * integrations with Colab, Jupyter Lab
  * Collaboration
    * Teams screenshare
  * fastcore stuff, especially L

  If time: review Lab 1 + extensions


Read:: Finish reading [DL4C chapter 3](https://nbviewer.jupyter.org/github/fastai/fastbook/blob/master/03_ethics.ipynb); **Reading Quiz**

===
Topic:: Conceptual and Practical Review

Due:: Reflection 3

Discussion:: Reply in last week's Discussion

===
Topic:: Exploring Tensors

===
Topic:: Modeling Basics

Watch:: [Lesson 3 video](https://course.fast.ai/videos/?lesson=3)

Read:: [DL4C chapter 4](https://nbviewer.jupyter.org/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) until "MNIST Loss Function" **Reading Quiz**

===
Topic:: Modeling Basics

Note:: Reflection delayed till next week

Note:: Add and upvote [application areas](https://calvincollege.sharepoint.com/sites/Section_77915/_layouts/15/Doc.aspx?sourcedoc={11c65f0d-7020-4c67-a7b2-93a5521628a6}&action=edit&wd=target%28_Collaboration%20Space%2FWeekly%20Notes.one%7Cf65e590f-924e-461a-ad2d-681cc376dd7c%2FApplication%20Areas%7C334a318a-1626-4e37-91fd-6bf983ef82d4%2F%29&wdorigin=703)

===3/4/2021
Quiz:: Technical Check-in

Released:: [Portfolio Repos](https://classroom.github.com/a/t9EfXnfw)

===
Read:: The rest of chapter 4

Watch:: The first hour of the [Lesson 4 video](https://course.fast.ai/videos/?lesson=4)


===
Watch:: The rest of the [Lesson 4 video](https://course.fast.ai/videos/?lesson=4) (masks postlude optional but interesting)

Read:: ch4 starting at "MNIST loss function", chapter 5 until "Model Interpretation"

Maybe the 3B1B YouTube videos?

===
Topic:: Chapter 5 review

===
Topic:: Lab

Spotlight:: [Taming Transformers](https://compvis.github.io/taming-transformers/)


===
Topic:: Lab

Read:: Rest of chapter 5, chapter 6

Watch:: [Lesson 6](https://course.fast.ai/videos/?lesson=6)

===
Topic:: Discussion and review

===
Topic:: Lab

Spotlight:: [Project Suggestions](/project)

Due:: Fundamentals 000-008 (suggested due date)

===

Lab:: Logistic Regression

Read:: Chapter 7 (active reading optional); Chapter 8; cumulative reading quiz


===
Topic:: Discussion on Facial Recognition Data

Spotlight:: [PapersWithCode Newsletter](https://paperswithcode.com/newsletter/)

Due:: Project Proposal Drafts

===
Topic:: Nonlinear Regression

===
Topic:: Collaborative Filtering

Read:: Through chapter 9

Watch:: [Lesson 7](https://course.fast.ai/videos/?lesson=7)

===
Topic:: Embeddings

===
Topic:: Collaborative Filtering and Embeddings in code

===
Topic:: Predictive Text

===
Topic:: Language Processing 1

Read:: chapters 10 and 12 (skim the `xx` tokenization details; feel free to stop training early)

Watch:: [Lesson 8](https://course.fast.ai/videos/?lesson=8)

Notes:: [Jay Alammar](https://jalammar.github.io/) ([YouTube](https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)) has made some nice visual explanations of language models.

===
Discussion:: Recommender Systems

===
Lab:: NLP

===04/13/2021
Opportunity:: [Human-Centered AI: Reliable, Safe and Trustworthy](https://iui.acm.org/2021/hcai_tutorial.html) (tutorial at Intelligent User Interfaces conferences)

===

advising day

===
Topic:: Modern language models

===
Topic:: Adversarial Learning

===
Topic:: Human-AI Interaction (explainability, interpretability, etc.)

===
Topic:: Fairness

https://cacm.acm.org/magazines/2021/4/251365-the-impossibility-of-fairness/fulltext

===
Topic:: Reinforcement Learning

Read:: [The Surprising Creativity of Digital Evolution](https://arxiv.org/abs/1803.03453v4)

===

===

===
Topic:: Unsupervised and Self-Supervised Learning

===

===

===endofcal
