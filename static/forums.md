---
title: "Forum posts"
---

## Final Email

Great work on projects! Prof. Vander Linden was eavesdropping on our presentations and spoke favorably afterwards. You should all have comments on all the parts in Moodle. I'd encourage you to turn your reports into blog posts and refer to them when applying for jobs or grad school.

Final grades are now posted. (Moodle is accurate; Self Service has a few errors but I've already asked the registrar to fix them.) They are almost all exactly what we discussed in the debriefs, but in some cases I assigned a higher grade after reviewing your work more comprehensively.

I'll leave the [feedback survey](https://calvin.co1.qualtrics.com/jfe/form/SV_73S6Vg5n43TuE7k) open for a few more days. I'll be studying the critical comments to help prioritize my list of dozens of things to change next year, and the positive ones to make sure those changes don't unintentionally break something that worked.

For those who want to go further or deeper in AI, I'd love to help:

* I'll be working on a few things over the summer that you could plug into.
* Rising seniors might choose one of [my senior projects](https://cs.calvin.edu/courses/cs/396/proposals/).
* If there's interest, we could start an AI reading group next year.
* Let me know if you're interested in helping develop materials for next year's AI class.

If you want to keep your portfolio repo, I recommend that you move it to your own GitHub account. The easiest way is to copy the files to a new repo, but if you'd like to move the existing repo, ask me and I can give you admin access to your repo.

Finally, thanks to each of you for your investment and perseverance in our learning community this semester, despite all of its challenges. May you be equipped to do the good work that God has for you, whatever it may be.


## Teams note for debrief

Hi, you've booked a ____ debrief/grading meeting with me. I'll be on campus so we can do in-person or online according to your preference; let me know. At that meeting we'll discuss the project and the final reflection, so those materials should be submitted on Moodle by that time. I don't see a final reflection from you yet, so let me know if you need to reschedule.

## More end-of-semester notes

To organize the rest of our time together, I have posted a few items on Moodle:

* Your main project materials (the technical report and supporting materials)
* Your *non-technical explanation* of the technology you're using
* Your *summary of a social/ethical discussion* we've had
* A *final reflection*, for us to discuss at your debrief / grading meeting.
* The [feedback survey](https://calvin.co1.qualtrics.com/jfe/form/SV_73S6Vg5n43TuE7k), which you have through next week to complete.

If you have not yet signed up for a grading/debrief meeting, please do so [**here**](https://outlook.office365.com/owa/calendar/Arnoldmeetings@calvincollege.onmicrosoft.com/bookings/).

Remember to also complete your Calvin course evaluation by end-of-day Thursday.

I'm really looking forward to seeing all of you at our showcase (Thursday 9am), and anyone who can make it, in person afterwards. It's been an honor to share this semester with you all.

## End of Semester Notes

#### Projects

First, a compromise about project **presentations**: we will do the primary event **online** to be hospitable to those who need that. But those who are on campus can informally gather right after the presentations, including lunch outside (weather permitting).

Take note of the recently [revised description](https://cs.calvin.edu/courses/cs/344/ka37/project/) of the **components of the project** on the website.

I want to support you in making awesome projects. But you need to proactively reach out---and many but not all teams have done that.

-   [**Sign up**](https://outlook.office365.com/owa/calendar/Arnoldmeetings@calvincollege.onmicrosoft.com/bookings/) **for a time to meet with me**. (Use "Short chat" or "Longer chat" depending on what you need.) I'm still figuring out how to get that app to sync with my calendar correctly, so apologies in advance if I need to reschedule a meeting with you.

-   **Some update on project is expected by end of day tomorrow**. If you're not able to meet with me by then, at least a Teams note is expected.

-   I'll have a good amount of availability next Monday-Wednesday for additional project support. Use the same sign-up link. Once you sign up, send me a Teams chat if you'd like to meet in person, otherwise I'll call you at that time.

#### Course Survey

I'd like to have your input as I revise this course for next year. **Please find some time to fill out [this survey](https://calvin.co1.qualtrics.com/jfe/form/SV_73S6Vg5n43TuE7k) sometime in the next two weeks**. It's moderately long and takes some thought, but the system should save your progress as long as you're using the same browser.

#### Debrief and Grading Meetings

Please sign up for a debrief and grading meeting with me late next week or early the following week, at the [same link](https://outlook.office365.com/owa/calendar/Arnoldmeetings@calvincollege.onmicrosoft.com/bookings/) as above. Be prepared to talk about what you've learned in this course and offer a suggested grade and evidence to back it up.

## Starting to Wrap Up

Last full week of class!! (Next Friday is reading day.)

**What you need to do this week**:

-   Give feedback on project updates

    -   Point out what's cool, ask questions, give suggestions.

    -   Some updates are missing; get them in ASAP.

-   Read and watch: the main ones are first on the [calendar](https://cs.calvin.edu/courses/cs/344/ka37/).

    -   **Mon**: [Stop doing "Explainable" ML](https://www.youtube.com/watch?v=I0yrJz8uc5Q) (it's short)

    -   **Wed**: Lecture 6 of [MIT 6.S191](http://introtodeeplearning.com/) (video or slides, whichever you have capacity for)

    -   **Fri**: Lecture 5 of [MIT 6.S191](http://introtodeeplearning.com/) (same)

-   **Keep working through Lab 5; no submission is needed**. Review Fundamentals 013 solutions if you're struggling with what this is predicting. (If you're interested in an extension of that to, e.g., generating images, ask me. This can be a fallback if your current project doesn't work out.)

I've noticed that everyone seems to have low capacity for new material. So aside from finishing projects, we will have **no more new programming assignments**. Instead, we will focus on reinforcing where we've gotten. Our class time will shift towards review, Q&A, and open lab time to work on projects or past work.

One way we'll reinforce what we've learned is by focusing on our third course objective: **communication** with peers and the general public. So there will be two remaining assignments:

1.  Your project submission should include a **short explanation of the technology you build on** for a nontechnical audience.

    -   You may choose to do this on a different technology instead; ask me.

    -   The explanation should make sense without reference to the rest of your project, though you may use the project as an example.

2.  Summarize, for a non-technical audience, one of the discussions we've had on the social and ethical context of AI.

    -   You may choose a topic we haven't discussed also; ask me.

    -   You may also incorporate this into your project submission if it's related.

I'm also inviting creative ideas for how to support your project work. For example:

-   Is anyone interested in having a "hack session" on a few specific projects during class time?

-   Would anyone be interested in project hack sessions outside of class time (e.g., a time where a bunch of us hang out on a Teams call or a Discord and just try to get stuff working)?

See you tomorrow!

## Generative Models

tl;dr: vote for [which assignment to review tomorrow](https://forms.office.com/Pages/ResponsePage.aspx?id=uUljdRAGAUuReypKwQ35Rw0bDGF2ImlDp6FjI7QrXehUMjAzTVRSTjJFSFBDRFExUkVQN0c4V0M0Ni4u) and [what to do a lab on this week](https://forms.office.com/Pages/ResponsePage.aspx?id=uUljdRAGAUuReypKwQ35Rw0bDGF2ImlDp6FjI7QrXehUOEQwNDNSMFJBOUQ2RVlLV01SOU9XM0FBNy4u)

This week we'll finish talking about generating images, talk more about generating text, and get some practice.

-   On **Monday** we'll finish the [Generative Models lecture](https://cs.calvin.edu/courses/cs/344/ka37/slides/2021-04-16%20Generative%20Models.pdf). We'll also **review** some past assignments; please [vote for which one](https://forms.office.com/Pages/ResponsePage.aspx?id=uUljdRAGAUuReypKwQ35Rw0bDGF2ImlDp6FjI7QrXehUMjAzTVRSTjJFSFBDRFExUkVQN0c4V0M0Ni4u) by 10am.

-   On *Wednesday* we'll discuss how to actually generate text using language models, and discuss one of the most important concepts in deep learning recently: **attention**. Optional but encouraged prep:

    -   Watch: [fast.ai Transformer lecture](https://www.youtube.com/watch?v=AFkGPmU16QA&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=19) (from the [NLP course](https://www.fast.ai/2019/07/08/fastai-nlp/))
    -   Read: [Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)

-   [Project Milestone 3](/activities/project-milestone-3) videos are due Thursday.

-   On *Friday* we'll do a lab of some sort. We've talked about a lot; what do you want practice with? It would be helpful to have your input on [this survey](https://forms.office.com/Pages/ResponsePage.aspx?id=uUljdRAGAUuReypKwQ35Rw0bDGF2ImlDp6FjI7QrXehUOEQwNDNSMFJBOUQ2RVlLV01SOU9XM0FBNy4u) by Tuesday.

(I'd originally thought to discuss fairness some this week, but I'm not yet fully happy with the set of readings. We'll do it next week.)

------------------------------------------------------------------------

So far we've been looking at AIs that take in a single (but maybe complicated) thing, like an image, and output a single simple thing (a classification label, a couple of numbers, etc.). Last week we looked at language models, where the AI can read a *sequence* of words (er, *tokens*) and output a guess of the next token.

We'll come back to delve more into language models, but since several final project teams want to generate things, we'll take a natural tangent to look at AIs that generate things. We already saw how we can make a language model generate a long sequence by repeatedly asking for the next word; we'll explore those more and also look at two related approaches for generating images / sound / video: Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).

## Week 9 mid-week

A few updates:

-   Reflection 8 is finally fully online (Moodle and website), sorry about that! If you need more time because of that, let me know.

-   I forgot to announce an exciting opportunity next Tuesday: a livestreamed tutorial on [Human-Centered AI](https://iui.acm.org/2021/hcai_tutorial.html) by one of the leaders in the field of human-computer interaction. I'm sad I'm not able to make it; can anyone attend some part of it and share some highlights with the rest of us?

-   The fast.ai materials on NLP are too low-level, so we're going to switch sources. This will be mainly relevant for Monday, but you can get a head start now.

    -   For *conceptual* coverage, **watch Lecture 2** (or just read the slides) from the [MIT Intro to Deep Learning course](http://introtodeeplearning.com/). I recommend also skimming Lecture 1 since it might be a helpful review.

    -   For *code*, we'll use [HuggingFace Transformers](https://huggingface.co/transformers/). Have a look at [this notebook](https://colab.research.google.com/github/huggingface/transformers/blob/master/notebooks/03-pipelines.ipynb) to see what's possible overall, and [this notebook](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) on text generation relevant to what we discussed today.

-   Several groups are interested in doing GANs, so we'll talk about that some next week. I haven't decided whether to do in Monday or Friday (Wed is advising day). But you can go ahead and **watch Lecture 4** on the MIT course.

Did anyone try Robot Mind Meld?

## Week 9: NLP

Last week we saw how *embeddings* are a super-useful tool for letting your AI refer to individual things in the real world, like people, movies, and words. This week we'll look more at words, especially focusing on how we can analyze and predict *sequences* of words. We'll focus mostly on *what* we're asking our models to do (predict the next word, classify a sequence); next week we'll look at *how* models do that (RNNs, LSTMs, and Transformers).

-   **Tech Reading**: By Wednesday, please have chapter 10 read in detail and chapter 12 skimmed.

    -   **Come to class with your questions about the reading**.

    -   skim the `xx` tokenization details; feel free to stop training early when doing active reading

    -   [Jay Alammar](https://jalammar.github.io/) ([YouTube](https://www.youtube.com/channel/UCmOwsoHty5PrmE-3QhUBfPQ)) has made some nice visual explanations of language models.

-   We're going to have a **discussion on recommendation systems**! See [instructions](https://cs.calvin.edu/courses/cs/344/ka37/activities/discussion-recommender-systems/) for some suggested readings.

-   **Fundamentals**: I (finally) posted two more on regression and classification. They cover some of the most useful things to remember about the tabular modeling that you saw in Chapter 9, unhitched from fastai so you can use them anywhere.

Here's what's up on the schedule.

-   **Monday**: I gave an abbreviated version of the presentation I gave when I defended my PhD research dissertation, about predictive text and what it does to people.

-   **Wednesday**: Q&A about chapter 10.

-   **Friday**: Discussion about recommender systems. [Reflection 8](https://cs.calvin.edu/courses/cs/344/ka37/activities/reflection-8/) due. (We skipped Reflection 7.)

-   **Monday**: NLP Lab

Please continue to work on projects; I'm working on getting feedback on proposals.

For a lighter take on word embeddings and language modeling, try [this improv game](http://robotmindmeld.com/).

## Week 8: Collaborative Filtering

Our first few weeks focused on data, then we spent a few weeks on how models work in general; now it's time for applications! We'll start with recommendation systems, which have had a big impact on many of our lives. Since that's a kind of tabular data, we'll also discuss some of the classic approaches to machine learning on tabular data (decision trees, random forests, and other methods). This is the "bread and butter" of how many organizations use machine learning.

Next week we'll start with natural language processing---my personal favorite use of machine learning. We could spend a whole class on that, but I'll try to keep it to 2 weeks so we have time for some other topics: GANs, explainability and other human+model interaction concerns, and reinforcement learning (learning to act).

-   **Reading**: back to fastai for two more weeks. This week is [Lesson 7](https://course.fast.ai/videos/?lesson=7), which gets us through chapter 9.

    -   Instead of a reading quiz, I'll post some Fundamentals notebooks to help you practice some of the skills I think are most important from these chapters.

-   **Monday**: Lecture on recommender systems (collaborative filtering). (No lab, to take a break.)

-   **Wed**: Lecture on tabular data

-   **Fri**: Lab on Tabular Data and embeddings.

**Project proposals** have generally been looking good, though many could benefit from being more specific about what data and approach to try. Start with some existing example and build on it or adapt it. I hope to finish giving feedback on these today.

**Expectations**: I dropped a few things last week (e.g., Thursday quiz, more Fundamentals) for all of our sanity. Things to do this week:

-   Finish the reading

-   Finish Lab 4

-   A few Fundamentals notebooks (hopefully posted by Monday)

-   Quiz Thursday

-   Reflection due... how about Thursday or Friday? What do you think?

## Week 7

This week, we're reviewing and consolidating what we've learned about modeling and learning by gradient descent, and (if all goes well) applying it to a new task (recommending stuff to people).

-   **Reading**: as mentioned in class, we're taking a week off from the Fast.ai grind. Instead:

    -   If you didn't get to chapter 8 last week, get to it sometime this week.

    -   Have a leisurely look back at Chapter 7 (which we'd skipped); instead of trying to replicate it, just focus on the core insights:

        -   wisely subset your data

        -   learn how to decode complicated-sounding papers into simple ideas

        -   messiness in your data might actually be helpful (especially Mixup, Label Smoothing, and Test-Time Augmentation)

    -   There's a cumulative reading quiz on Moodle to remind you of a few key ideas. Some of it will be helpful to review before class on Monday.

-   Our discussion of Facial Recognition Data is on [Moodle](https://moodle.calvin.edu/mod/forum/view.php?id=1216990); please be prepared to share some highlights when we discuss this in class on Wednesday.

    -   I enjoyed watching Coded Bias on Thursday night! If you missed that and still want to watch, there's signs that it may be available for streaming on demand on PBS even after the Monday 10pm screening.

    -   IndieLens posted a [Discussion Guide](http://bit.ly/ILPOP-CODEDBIAS-Discussion-Guide) for the film. Please feel free to bring up any points or questions from there in our discussion, even if you didn't watch the film. The film has a pretty liberal slant, so I'd be particularly interested in conservative perspectives.

-   I made a [video walkthrough for Lab 3](https://www.youtube.com/playlist?list=PLYvyo-La3zBN8qoyCf3l0RRaopUa0KXPG). It was fun, good idea whoever that was who suggested it on Piazza.

-   By now you should have most of the Fundamentals notebooks submitted in Moodle. I'm gradually posting [solutions](https://github.com/kcarnold/cs344/tree/main/portfolio/fundamentals); I'll let you know when they're done. Also stay tuned for a few new notebooks this week.

**What's up this week?**

-   **Mon**: Probably a lab on Logistic Regression 3 ways, to level up and consolidate concepts of modeling and gradient descent, get briefly introduced to scikit-learn (more in chapter 9), and train our first neural net

-   **Wed**: Continue the discussion of Facial Recognition Data that we started on Moodle ([Facial Recognition (Structured Discussion 2)](/activities/discussion-2-facial-recognition)).

    -   Due: Project Proposal Drafts; Reflection 6

-   **Fri**: Collaborative Filtering (chapter 8)

See you on Monday!

## Week 6 mid-week

A few mid-week things:

First, I'm sorry for my harsh and insensitive comment during class today about those who didn't yet do the Lab 2 post-lab. Since students are asking for more clarity about expectations, clearly there is something lacking about my communication in that regard. But rather than seeking to understand the situation, I just expressed frustration about it. Please forgive me. And if this expectation wasn't clear to you, I would welcome any suggestions if you have them.

Reflection 5 is due today as usual. I've clarified the assignment for what is (not) expected about Lab 3. Also, although there are a few potential ways you can engage Context this week (including the project ideas forum, the current discussion forum, and replying in previous forums), it hasn't been as lively as usual. So you may choose to just leave Context blank this week; there's built-in allowance in our grading system for that. (Don't **forget your Reflection 4 updates** if you were meaning to come back and fill in some things.)

Next week's Context will be on facial recognition---in part because there's two screenings of Coded Bias happening. **The first one is tomorrow evening**---see the [discussion assignment](https://cs.calvin.edu/courses/cs/344/ka37/activities/discussion-2-facial-recognition/) for details.

Finally, I've posted submission assignments on Moodle for all the Fundamentals notebooks. Hopefully it should only take a few minutes to copy and paste the relevant URLs from github. I've set all of them to be "due" at the end of this week, which I think is a reasonable expectation but it's ok if you're still catching up on these. (And please let me know if they're taking much longer than 15 minutes each once you've understood the concept.)

## Week 6: Make it Train!

We've studied what data goes into a computer vision model, what output comes out and how that depends on the data, and the basic mechanics of how these kinds of models learn. Now we're going to hook it all together and learn how to get computer vision models to do what we want. After this, we'll look at different types of models (finally something other than a ResNet! and btw, what's a ResNet?), starting with collaborative filtering and then getting into natural language processing.

Please watch the Lesson 6 video and read the corresponding parts of the book (chapter 5 and 6 for now, chapter 8 by end of this week / beginning of next week). The video is long, but has some natural stopping points at chapter boundaries, so take breaks! (We're skipping Chapter 7, but it is a short read if you're interested.)

No reading quiz this week; instead, I've added some Fundamentals notebooks. Skip `004-data-manip-jsonlines` if you're pressed for time; `005-image-ops` is exactly what we did in class two weeks ago, and `006-compute-grad` is both PyTorch practice and what might be a fresh take on the linear regression that you learned in stats or high school. A few more are coming (I got in a fistfight with git). If you notice anything surprising about your repo, message me; I may have messed something up with git.

Remember the **Lab 2 post-lab**! You'll need this for Wednesday.

**Homework 2** is out! It's a chance to practice your tensor and gradient descent skills. You already know enough to make a first pass at it, and what you learn this week will help you make it better. Have a look and post your questions!

This week:

-   We did the first part of Lab 3 together on Friday, on **Monday** you'll have it to yourselves. You may also choose to use that time to work on Fundamentals notebooks (collaboration is welcome there too).

-   On **Wednesday** we'll debrief what we learned in Labs 2 and 3. I may ask you to write about something and/or explain something to a neighbor, so prepare what you'll need for that.

-   On **Friday** we'll do another application spotlight, finish anything we didn't get to on Wednesday, and do more lab work if time permits.

Reflection 5 assignment is coming, but it'll be mainly asking about your Lab 2 and 3 and Fundamentals notebooks.

For Context this week, some of you may choose to go back to the Week 4 forum (which was relatively quiet). Others may choose to start exchanging project ideas; I posted a Discussion forum for that.

## Week 5: How Models Learn; Getting Structured

This week we continue peeling the Machine Learning onion to ask: how can models respond to feedback from data in order to improve themselves? So we'll continue practicing with loss functions, backpropagation, and gradient descent. These are the core computational building blocks that have powered most of the advances in AI in the past decade, so your effort to get comfortable with these will pay off.

It seems that some people are finding it difficult to put in the self-directed effort that this class requires. Perhaps it's hard because other classes and responsibilities have firmer expectations and due dates. So a few changes are coming to make this class more structured:

-   We'll try making the reflections more objective and quantitative, starting with this week's [reflection](https://cs.calvin.edu/courses/cs/344/ka37/activities/reflection-4/) (see link). Since this is short notice and it'll probably take longer than usual, here's what we'll do: please submit an initial version of your reflection by Wednesday the 10th as usual with *something* filled out in each category, but leave placeholders as needed and revise as desired through the following Wednesday.

-   This week there's a reading assignment as usual, but there's no reading quiz. Instead, I'm asking you to actually submit all of your active reading notebooks so far in your Portfolio repos; see the `README` in the `readings` folder there. **Please Piazza or text me questions that come up when reading.**

These new elements may expose some ways that you let some things slide in this class. There is grace for you, and I have good reason to hope that you can catch up. If you're concerned about something, remember that it's literally my job to be here for you, so just **send me a quick Teams message** and we can chat.

In class this week (all HL102): **Monday** we'll finish Lab 2 together, **Wednesday** we'll go over some things from the reading (including the team-competition analogy that I previewed last week), and **Friday** we'll do more new lab work, probably working through the portfolio exercises I'll post this week.

## Week 4 Thursday

As discussed in class yesterday, the **portfolio repos are now live. Claim yours [here](https://classroom.github.com/a/t9EfXnfw)** (link is also on the class calendar). To start, go in "fundamentals", read the README, and get started soon; first few that are already up there should be pretty easy. I'll push new notebooks every few days.

Also, a reminder since we'd skipped a few weeks: this week's [**check-in quiz**](https://https//moodle.calvin.edu/mod/quiz/view.php?id=1208066) **has been posted**.

Finally, to reduce the variance in reflection grades, the next reflection will have a more objective rubric. Since it will require referring to the portfolio and quiz (as well as the hw1 revision), I'm **delaying the due date for the reflection** until next Wednesday (i.e., we're skipping a week for reflections).

(Sorry for the midweek updates this week; I aim for these to be once a week.)

## Week 4

Happy Saturday everyone! As I mentioned in class, I'm sorry I'm so behind in giving you feedback, and I'm sorry for not posting a check-in quiz in the usual time this week (I'll post one by Monday, which you can attempt whenever works for you).

**Where we are**: We started off treating everything as a black box (that block of code that fit the pet classifier) and we've been gradually peeling off layers of the onion:

-   First we explored *data*: how do we get data, in a useful form? How does the data affect what the model learns?

-   Now we're exploring the model's *outputs*: how do we measure what makes a good output, and how do we get the model to update itself to make its output better?

-   After this we'll peel off the covers on the model itself.

As we get into more technical depth, some people may find the material harder. Others may actually find this easier for various reasons, though. So help each other! -- ask questions, post hints, etc.

**This week**:

-   **Prep**:

    -   All of the Lesson 3 video and part of Chapter 4; see the Calendar and Reading Quiz for details.

    -   Also, start reading the [Facial Recognition discussion](https://cs.calvin.edu/courses/cs/344/ka37/activities/discussion-2-facial-recognition/) readings.

    -   Sometime this week, try to revise your Homework 1 in light of our discussions, both about decisions/data/experimentation/variation and about `DataLoader`s.

-   **Monday**: We'll be back in classroom, reviewing some of the reading together. Have your active reading notebooks handy and come with your questions.

-   **Wednesday**:

    -   We'll overflow from Monday as needed, then discuss some highlights from the facial recognition discussion.

    -   Another reflection due. Keep it brief, but do try to discuss your HW1 revision.

-   **Friday**: Lab (in the classroom space) on fitting models with gradient descent. If you're able to finish Chapter 4 reading by then, it'll be helpful; otherwise get it over the weekend.

## Week 3

Happy Saturday everyone! I'm enjoying reading your reflections and feedback about the class. I'm hearing from many people that they'd like some more discussion about technical concepts than they're getting from the reading and videos. In light of that, I'm making a few tweaks: this week we'll do a **lecture on Monday** instead of a lab.

In case you missed it, the reading assignment for this weekend is to **finish Chapter 3**. There's a [reading quiz](https://moodle.calvin.edu/mod/quiz/view.php?id=1203438) on Moodle as usual. Depending on your comfort, you may choose to answer the questions there in **this week's [discussion forum](https://moodle.calvin.edu/mod/forum/view.php?id=1203582)** instead.

Speaking of which, [last week's discussion forum](https://moodle.calvin.edu/mod/forum/view.php?id=1200372) was a lot of fun---I may have spent too much time responding to your posts! But only a few people posted any replies. So this week I'll encourage you to **reply to other students**.

Also, thanks to someone asking, I realized I'd forgotten to link to my **office hours** calendar. I added that on the syllabus. You can always message me directly. I'll probably ask you to post about our discussion on Piazza too, because they're usually good questions that others would benefit from hearing too.

This week's deadlines (all informal except the reflections, as usual, but the reflections should mention all of them):

-   **Monday**:

    -   Reading Quiz 3

    -   Homework 1 (we'll discuss some in class tomorrow)

-   **Wednesday**:

    -   Reflection 3.

    -   Reply in Week 2 Discussion Forum

-   **Thursday**: Quiz 4 (I'll try to post this early so you can reference it in the Reflection, but no promises.)

-   **Friday**:

    -   Post in Week 3 discussion.

    -   I recommend getting started on Chapter 4 because it's more technical than the first few

-   **next Monday**: Reading Quiz 4 (on chapter 4).
