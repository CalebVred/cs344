# Next Year

## Objectives

* What AI solutions can be used on what problems?
* Processing large datasets?
* Model debugging strategies?

Social impact:

* Feedback loops
* Biases

### Knowledge

* Kinds of AI systems
* Components of systems
* Mathematical basis
* How outputs depend on data

### Skills

* Select an approach to solve a problem
* Map problem characteristics onto approach elements
* Implement approach in code

### Dispositions

* Treat data as both valuable and flawed
* Treat people as more than just data sources or targets to manipulate
* Investigate where data came from
* Think through how a system will affect people.
* Think about what the data doesn't include, what the algorithm ignores or de-emphasizes.
* Repeat experiments.
* Notice and document the decisions you're making.
* Seek understanding of what a system gets wrong (rather than just reporting numbers)

## High level

* Start with applications. Gradually deepen the code and concepts.
* Intentionally overlap application areas and even specific datasets between DATA 202 and CS 344.
* The material on interpretability and fairness/bias could have come much earlier in the semester.
* Remind students about the drivetrain approach for projects
* Specifically connect with *Reformed* tradition

## Materials

* The fast.ai textbook doesn’t encourage enough spending time with data (EDA)
* Use more of the HuggingFace stuff instead?


## Logistics

* Don't bother auto-pushing content to student repos.
* Use a single compute platform (Colab?)
* Use a single submission platform (Moodle?)
* Projects: meet earlier, get more specific

## Potential Resources

* [Applied Machine Learning course at Cornell Tech](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)

## Potential Activities

* Play with latent space / generation (projection, latent space math, )
* Logistic regression in NN (as same thing as linreg, just different loss and activation)
* Vision to text encoder decoder—with paraphrase setup both ways

## Low-Level Stuff

* More visualization tools.
    * Loss plots
    * Data exploration, e.g., class distribution
    * A "quick snapshot" of a dataset?
        * examples, clustered using pretrained embeddings?
    * Visualizing the results of learning:
* Batch size -- can use a bigger model.
* sklearn 011: Make sure to ask about *validation* set (See Andrew Feikema's submission)

### Project Debrief

* For a team project: what was their role?
* What's your 60-second self-reflection on your performance on the project?
* Ask students to describe their process; what was challenging and how overcame
